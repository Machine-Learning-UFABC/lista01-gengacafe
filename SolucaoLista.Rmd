---
title: "Solução Lista 01"
author: |
        | Nome: João Pedro Genga Carneiro
        | E-mail: joao.genga@aluno.ufabc.edu.br
        | Nome: José Roberto de Oliveira
        | E-mail: jose.r@aluno.ufabc.edu.br
        | (Não é preciso informar os RAs)
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,
                      fig.align='center',
                      cache=TRUE,
                      out.width = "60%",
                      out.heigth = "60%",
                      warning=FALSE,
                      message=FALSE)
options(width =70)

library(tibble)
library(dplyr)
library(tidyverse)
```

## Exercício 01


a) Problema de Classificação

Em problemas de classificação, o objetivo é prever a categoria de um certo dado fornecido com base em suas características. 
O algoritmo aprende a mapear as entradas (vetores de características) usando as informações passadas para eventualmente classificar esses dados nas saídas (rótulos).

Aplicações Possíveis:

# Diagnóstico Médico:

Descrição: Classificar pacientes como tendo ou não uma determinada doença com base em exames médicos.

Vetores de Características: Resultados de exames (por exemplo níveis de glicose, pressão arterial, idade, peso).

Rótulos: Diagnóstico positivo (1) ou negativo (0).

# Filtro de Spam:

Descrição: Classificar e-mails como spam ou não spam.

Vetores de Características: Frequência de palavras específicas, presença de links, endereço de e-mail.

Rótulos: Spam (1) ou não spam (0).

```{r, out.width="50%"}
knitr::include_graphics("/image.png")

b) Problema de Regressão
Em problemas de regressão, o objetivo é prever (portanto são usados em modelos preditivos) um valor contínuo com base em variáveis das quais tal valor é dependente, ou seja, costuma ser usado para previsão de tendências.
O algoritmo aprende a mapear as entradas (vetores de características) para definir as saídas (valores contínuos). 

Aplicações Possíveis:

# Previsão de Preços de Imóveis:

Descrição: Prever o preço de uma casa com base em suas características.

Vetores de Características: Tamanho da casa, número de quartos, localização, número de vagas.

Resposta: Preço do imóvel (veja, é um valor contínuo).

# Previsão de Temperatura: 

Descrição: Prever a temperatura em uma determinada localização e horário.

Vetores de Características: Dados meteorológicos (por exemplo pressão atmosférica, umidade, velocidade do vento).

Resposta: Temperatura.

# Previsão de Demanda:

Descrição: Prever a demanda por um produto em um determinado período.

Vetores de Características: Histórico de vendas, preço do produto, época do ano, menções em redes sociais.

Resposta: Intensidade da demanda.

c) Problema de Agrupamento (Clustering)

Em problemas de agrupamento, o objetivo é agrupar dados semelhantes em clusters sem a necessidade de rótulos pré-definidos.
O algoritmo aprende a mapear as entradas (vetores de características) para identificar padrões de dados.

Aplicações Possíveis:

# Segmentação de Produtos:

Descrição: Agrupar produtos com base em comportamentos de compra (por exemplo lâmina de barbear e creme de barbear).

Vetores de Características: Histórico de compras, produtos comprados juntos, produtos no carrinho, função do produto.

Resposta: Grupos de produtos.

# Organização de Documentos:

Descrição: Agrupar documentos semelhantes para facilitar a busca e organização.

Vetores de Características: Frequência de palavras, tópicos, autoria.

Resposta: Grupos de documentos.

# Fontes:

- https://www.datacamp.com/blog/classification-machine-learning
- https://www.seldon.io/machine-learning-regression-explained
- https://www.sciencedirect.com/topics/engineering/clustering-problem

## Exercício 02


## Exercício 03

``` {r}

knn_eucledean <- function(k, x, D) {
  D %>%
    mutate(dist = (x[1] - x_1)^2 + (x[2] - x_2)^2) %>%
    arrange(dist) %>%
    head(k) %>%
    count(y, sort = TRUE) %>%
    slice(1) %>%
    pull(y)
}

library(tibble)

set.seed(42)
D <- tibble(
  x_1 = rnorm(100, 1, 1),
  x_2 = rnorm(100, -1, 2),
  y = factor(sample(c("one", "two", "three"), 100, replace = TRUE))
)

head(D)
```
``` {r}
k <- 10


v1 <- c(1, 2)
knn_eucledean(k, v1, D)

v2 <- c(2, 1)
knn_eucledean(k, v2, D)

v3 <- c(0, 1)
knn_eucledean(k, v3, D)

v4 <- c(-2, -3)
knn_eucledean(k, v4, D)
```

## Exercício 04

``` {r}
data("iris") # Carrega o banco no ambiente global

iris <- as_tibble(iris) %>% # Converte para a dataframe tibble
  
select(Petal.Length,Sepal.Length,Species) %>% # Seleciona colunas da dataframe
  
rename( x_1 = Petal.Length, x_2 = Sepal.Length, y = Species) # Renomeia as colunas

head(iris)
```
```{r}
l_iris <- as.list(iris)

accuracy <- function(k) {
  predictions <- pmap_lgl(l_iris, function(x_1, x_2, y) {
  predicted <- knn_eucledean(k, c(x_1, x_2), iris)
    return(predicted == y)
  })
  
  correct_predictions <- sum(predictions)
  total_predictions <- length(predictions)
  
  accuracy <- (correct_predictions / total_predictions) * 100
  return(list(correct_predictions = correct_predictions, total_predictions = total_predictions, accuracy = accuracy))
}


accuracy_k10 <- accuracy(10)
accuracy_k1 <- accuracy(1)

cat("Total de acertos para k = 10:", accuracy_k10$correct_predictions, "de", accuracy_k10$total_predictions ,"ocorrencias \n")
cat("Acuracia para k = 10:", accuracy_k10$accuracy, "%\n")

cat("Total de acertos para k = 1:", accuracy_k1$correct_predictions, "de", accuracy_k1$total_predictions ,"ocorrencias \n")
cat("Acuracia para k = 1:", accuracy_k1$accuracy, "%\n")
```